# MDP-CS463
Markov Decision Processes
Jacob Pawlak

The state space:

s1	s2	s3	s4
s5	s6	s7	s8
s9	s10	s11	s12
s13	s14	s15	s16
 

The reward function:

0	0	3	10
0	5	0	60
5	10	5	0
45	0	0	5

The actions: up, down, left, right

Probabilities:

0.7 to succeed
0.2 to go to the opposite direction
0.1 to stay

you bounce back, if you hit the wall (4 outside edges)


^Technical specs of the project.


